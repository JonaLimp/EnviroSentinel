{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae36c5fa",
   "metadata": {},
   "source": [
    "### Preprocessing Sensor Data:\n",
    "- Load raw data\n",
    "- Resample & align\n",
    "- Clean missing / invalid values  \n",
    "- Scale features\n",
    "- Optional features\n",
    "- Save cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97433c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MStandardScaler\n",
    "\n",
    "path_file = Path.cwd().parent / Path(\"data/merged_data\")\n",
    "output_path = Path.cwd().parent / Path(\"data/processed_data\")\n",
    "\n",
    "if not output_path.exists():\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sensors_to_explore = [\n",
    "    'value_Luftfeuchte',\n",
    "    'value_Lautstärke',\n",
    "    'value_Temperatur',\n",
    "       ]\n",
    "stations_to_explore = [\n",
    "    'home_Klinga',\n",
    "    'Stadtteilbüro_Siemensstadt',\n",
    "    'PANGAEAs_SenseBox',\n",
    "    'Station_Kaiser',\n",
    "    'Schnus_Sense_Box'\n",
    "       ]\n",
    "\n",
    "n_rows = len(sensors_to_explore)\n",
    "n_cols = len(stations_to_explore)\n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "for file_path in path_file.iterdir():\n",
    "    file_name = str(file_path.name.split(\".\")[0])\n",
    "\n",
    "    if file_name not in stations_to_explore:\n",
    "        continue\n",
    "    print(file_name)\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df = df.sort_values('timestamp')\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    dataframes[file_name] = df\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6978546",
   "metadata": {},
   "source": [
    "## Delete unecessary colunns:\n",
    "\n",
    "In order to stick to the task and to not blow this project i decided to drop unecessary columns and just keep \"humidity\", \"temperature\" and \"sound volume\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1553f9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_columns = [c for c in df.columns if c not in sensors_to_explore]\n",
    "\n",
    "for df in dataframes.values():\n",
    "    for c in del_columns:\n",
    "        if c in df.columns:\n",
    "            df.drop(c, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4ee671",
   "metadata": {},
   "source": [
    "## Filling Missing Values\n",
    "\n",
    "For temperature and humidity interpolation and for sound volume ffill. Interpolation does not work for the humidity column, since it just refills the same values. I decided to keep the corrupted dat and flag it as an anomily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2cac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'value_Luftfeuchte'\n",
    "\n",
    "def remove_stuck_values(df, column, min, max, min_consecutive):\n",
    "    df_copy = df.copy()\n",
    "    df_copy.fillna(method='ffill', inplace=True)\n",
    "    mask = (df_copy[column] >= max) | (df_copy[column] <= min)\n",
    "\n",
    "    run_id = (mask != mask.shift()).cumsum()\n",
    "    run_lengths = mask.groupby(run_id).transform('sum')\n",
    "\n",
    "    stuck = mask & (run_lengths >= min_consecutive)\n",
    "    count = stuck.sum()\n",
    "\n",
    "    df.loc[stuck, column] = None\n",
    "    print(f\"[{column}] removed {count} stuck values below {min } or above {max} (runs ≥ {min_consecutive})\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def flag_flatline_runs(df, column, min, max, min_consecutive, flag_name=None):\n",
    "    # mask = df[column] == value\n",
    "    df_copy = df.copy()\n",
    "    df_copy.fillna(method='ffill', inplace=True)\n",
    "    mask = (df_copy[column] >= max) | (df_copy[column] <= min)\n",
    "    \n",
    "    run_id = (mask != mask.shift()).cumsum()\n",
    "    run_lengths = mask.groupby(run_id).transform('sum')\n",
    "\n",
    "    flatline = mask & (run_lengths >= min_consecutive)\n",
    "    \n",
    "    if flag_name is None:\n",
    "        flag_name = f\"{column}_flatline_flag\"\n",
    "\n",
    "    df[flag_name] = flatline.astype(int)\n",
    "    \n",
    "    print(f\"[{column}] flagged {flatline.sum()} flatline points alues below {min } or above {max} (runs ≥ {min_consecutive})\")\n",
    "    return df\n",
    "\n",
    "# Remove stuck 100% humidity if it lasts for 6+ hours (360 samples at 1-min frequency)\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"Processing {name}\")\n",
    "    # dataframes[name] = remove_stuck_values(df, 'value_Luftfeuchte', min= 1.,max=99., min_consecutive=180)\n",
    "    dataframes[name] = flag_flatline_runs(df, 'value_Luftfeuchte', min= 1.,max=99., min_consecutive=180) \n",
    "     \n",
    "    if column in df.columns:\n",
    "        print(f\"  Checking {column}: unique values = {df[column].nunique()}, min = {df[column].min()}, max = {df[column].max()}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ae787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_strategies = {\n",
    "    'value_PM2.5': lambda s: s.interpolate(method='time'),\n",
    "    'value_PM10': lambda s: s.interpolate(method='time'),\n",
    "    'value_Temperatur': lambda s: s.interpolate(method='time'),\n",
    "    'value_Luftfeuchte': lambda s: s.interpolate(method='time'),\n",
    "    # 'value_Luftfeuchte': lambda s: s,\n",
    "    'value_Beleuchtungsstärke': lambda s: s.interpolate(method='time'),\n",
    "    'value_UV-Intensität': lambda s: s.fillna(method='ffill').fillna(method='bfill'),\n",
    "    'value_Lautstärke': lambda s: s.fillna(method='ffill').fillna(method='bfill'),\n",
    "}\n",
    "\n",
    "for df_name, df in dataframes.items():\n",
    "    for sensor_name, method in fill_strategies.items():\n",
    "        if sensor_name not in df.columns:\n",
    "            continue\n",
    "        df[sensor_name] = method(df[sensor_name])  \n",
    "        dataframes[df_name] = df \n",
    "    print(f\"Any missing values left for {df_name}:  {df.isnull().any().any()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09e72db",
   "metadata": {},
   "source": [
    "I decided to do not interpolate the missing values for humidity, because filling methods would just introduce the same flat line that i tried to get rid of. Most modern ML algrotihm handle missing data quite well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f53bfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sensor in sensors_to_explore:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    for name, df in dataframes.items():\n",
    "        if sensor in df.columns:\n",
    "            sns.histplot(df[sensor], kde=True, label=name, stat=\"density\", bins=100, element=\"step\")\n",
    "    \n",
    "    plt.title(f\"{sensor} Distribution – All Stations\")\n",
    "    plt.xlabel(sensor)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend(title=\"Station\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d004eaf0",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d7e38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lag_features(df, columns, lags=[1, 5, 10]):\n",
    "    for col in columns:\n",
    "        for lag in lags:\n",
    "            df[f'{col}_lag_{lag}'] = df[col].shift(lag)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce6fd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dataframes.values(): \n",
    "    # Add time-based features\n",
    "    df['hour'] = df.index.hour\n",
    "    df['minute'] = df.index.minute\n",
    "    df['weekday'] = df.index.weekday  # 0 = Monday\n",
    "    df['is_weekend'] = df['weekday'].isin([5, 6]).astype(int)\n",
    "    df['is_daylight'] = ((df['hour'] >= 6) & (df['hour'] <= 20)).astype(int)\n",
    "    \n",
    "    # Add rolling statistics\n",
    "    window = 10  # e.g., 10 minutes\n",
    "\n",
    "    for col in ['value_Temperatur', 'value_Luftfeuchte']:\n",
    "        df[f'{col}_rolling_mean'] = df[col].rolling(window=window, min_periods=1).mean()\n",
    "        df[f'{col}_rolling_std'] = df[col].rolling(window=window, min_periods=1).std()\n",
    "\n",
    "        #Add differnece deltas\n",
    "\n",
    "        df[f'{col}_diff'] = df[col].diff()\n",
    "\n",
    "    # Feature engineering for 'value_Lautstärke' \n",
    "    df['sound_bin'] = pd.cut(df['value_Lautstärke'], bins=[0, 30, 60, 90, 120], labels=[\"very quiet\", \"quiet\", \"normal\", \"loud\"])\n",
    "\n",
    "    df['sound_high'] = (df['value_Lautstärke'] > 100).astype(int)\n",
    "    df['sound_silent'] = (df['value_Lautstärke'] < 10).astype(int)\n",
    "    \n",
    "    # Add lag features\n",
    "    df = add_lag_features(df, ['value_Luftfeuchte', 'value_Temperatur', 'value_Lautstärke'], lags=[1, 5, 10])\n",
    "    # Add flatline flags\n",
    "    df = flag_flatline_runs(df, 'value_Lautstärke', min=0, max=120, min_consecutive=60, flag_name='Lautstärke_flatline_flag')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac3245",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in dataframes.items():\n",
    "    df.reset_index(inplace=True)\n",
    "    df.to_csv(output_path / f\"{name}.csv\", index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envirosentinel-qOirRLpq-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
