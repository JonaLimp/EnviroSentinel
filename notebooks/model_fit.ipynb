{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66dd38d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jonas-limpert/Projects/EnviroSentinel/notebooks\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MODEL_PATH' from 'config.config' (/home/jonas-limpert/Projects/EnviroSentinel/config/config.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(Path\u001b[38;5;241m.\u001b[39mcwd())\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Now import\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MODEL_DIR\n",
      "File \u001b[0;32m~/Projects/EnviroSentinel/config/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MODEL_PATH, SCALER_PATH, PROJECT_ROOT\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'MODEL_PATH' from 'config.config' (/home/jonas-limpert/Projects/EnviroSentinel/config/config.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import joblib\n",
    "import sys\n",
    "\n",
    "# Manually set project root once\n",
    "PROJECT_ROOT = Path().resolve().parents[1]\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "print(Path.cwd())\n",
    "\n",
    "\n",
    "# Now import\n",
    "from config.config import MODEL_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606fdb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"/home/jonas-limpert/Projects/EnviroSentinel/data/processed_data\")\n",
    "\n",
    "dfs = {}\n",
    "for file in data_path.iterdir():\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.update({file.name.split(\".\")[0]: df})\n",
    "print([k for k in dfs.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6ac9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IsolationForest(\n",
    "    n_estimators=100,        # Number of trees\n",
    "    max_samples='auto',      # Subsampling size per tree\n",
    "    contamination=0.01,      # Estimated fraction of outliers\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43faf292",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "for df_name, df in dfs.items():\n",
    "    df['station'] = df_name\n",
    "    df_encoded = pd.get_dummies(df, columns=[\"sound_bin\"], drop_first=True)\n",
    "    df[\"sound_bin_encoded\"] = encoder.fit_transform(df[[\"sound_bin\"]])\n",
    "    df['station_encoded'] = encoder.fit_transform(df[['station']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c72e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = dfs.pop('Station_Kaiser')\n",
    "\n",
    "combined_df = pd.concat([\n",
    "    df for df in dfs.values()\n",
    "    ], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dcfc33",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccd4cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "split_idx = int(len(combined_df) * 0.8)\n",
    "train_df = combined_df.iloc[:split_idx].copy()\n",
    "validation_df = combined_df.iloc[split_idx:].copy()\n",
    "\n",
    "numeric_columns = combined_df.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(train_df[numeric_columns])\n",
    "X_val_scaled = scaler.transform(validation_df[numeric_columns])\n",
    "\n",
    "model = IsolationForest(contamination=0.05, random_state=42)\n",
    "model.fit(X_train_scaled)\n",
    "\n",
    "validation_df['anomaly'] = model.predict(X_val_scaled)\n",
    "train_df['anomaly'] = model.predict(X_train_scaled)\n",
    "\n",
    "validation_df.to_csv(\"/home/jonas-limpert/Projects/EnviroSentinel/data/validation_df.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a478039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "validation_df['timestamp'] = pd.to_datetime(validation_df['timestamp'])\n",
    "validation_df.set_index('timestamp', inplace=True)\n",
    "\n",
    "sensors_to_explore = [\n",
    "    'value_Luftfeuchte',\n",
    "    'value_Lautstärke',\n",
    "    'value_Temperatur',\n",
    "]\n",
    "\n",
    "    \n",
    "\n",
    "# Loop through each sensor\n",
    "for sensor in sensors_to_explore:\n",
    "    if sensor in validation_df.columns:\n",
    "        anomalies = validation_df[validation_df['anomaly'] == -1]\n",
    "        \n",
    "        plt.figure(figsize=(15, 4))\n",
    "        plt.plot(validation_df.index, validation_df[sensor], label=sensor, color='gray')\n",
    "        plt.scatter(anomalies.index, anomalies[sensor], color='red', label='Anomaly', s=20)\n",
    "        plt.title(f\"Anomaly Detection: {sensor}\")\n",
    "        plt.xlabel(\"Timestamp\")\n",
    "        plt.ylabel(sensor)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eb55a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Ensure timestamp is datetime and used as index\n",
    "train_df['timestamp'] = pd.to_datetime(train_df['timestamp'])\n",
    "train_df.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Step 2: Define which sensors to visualize\n",
    "sensors_to_explore = [\n",
    "    'value_Luftfeuchte',\n",
    "    'value_Lautstärke',\n",
    "    'value_Temperatur',\n",
    "]\n",
    "\n",
    "# Step 3: Loop over each station and each sensor\n",
    "for station_name in train_df['station'].unique():\n",
    "    station_df = train_df[train_df['station'] == station_name]\n",
    "    \n",
    "    for sensor in sensors_to_explore:\n",
    "        if sensor in station_df.columns:\n",
    "            anomalies = station_df[station_df['anomaly'] == -1]\n",
    "            \n",
    "            plt.figure(figsize=(15, 4))\n",
    "            plt.plot(station_df.index, station_df[sensor], label=sensor, color='gray')\n",
    "            plt.scatter(anomalies.index, anomalies[sensor], color='red', label='Anomaly', s=20)\n",
    "            plt.title(f\"Anomaly Detection: {sensor} – {station_name}\")\n",
    "            plt.xlabel(\"Timestamp\")\n",
    "            plt.ylabel(sensor)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf60b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import joblib\n",
    "ModelPath = Path(PROJECT_ROOT) / 'model'\n",
    "ModelPath.mkdir(parents=True, exist_ok=True)\n",
    "print(ModelPath)\n",
    "# Save model\n",
    "joblib.dump(model, ModelPath / 'isolation_forest_model.pkl')\n",
    "\n",
    "# Save scaler (if you're using StandardScaler or similar)\n",
    "joblib.dump(scaler, ModelPath / 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34d4999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dce1abb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envirosentinel-qOirRLpq-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
